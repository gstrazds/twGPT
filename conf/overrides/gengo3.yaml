# @package _global_
# overrides for main config from config.yaml

gpus:  # set to a single int n to auto-select n gpus from all available, or to a list of gpu indices e.g. [0,1,2,3]
#  - 0  # yaml format for a list
#  - 1
  - 2
  - 3

gpt:
  block_size: 512  # spatial extent of the model for its context
  n_embd: 512

trainer:
  batch_size: 32
  max_epochs: 4
  learning_rate: 3e-4
  patience: 20
  save_top_k: 20
#  val_check_interval: 0.2
#  limit_val_batches: 10000  # this should cover all of our current validation set (but maybe not the test set?)

eval:
  root_dir: /work2/gstrazds/ftwc
  checkpoint: ${cwd_path}/saved_models/instrgpt-epoch=2-step=0-train_loss_step=0.024-val_loss=0.574.ckpt
  # instrgpt-epoch=2-step=0-train_loss_step=0.024-val_loss=0.574.ckpt   # 91.97% win:72/124 lost:22 (w56/222)
